NAME: Chris Baker
EMAIL: 
ID: 

(List of Files are after the Answers to Questions)
README:

**Questions

*2.1.1:

-While a thread is being created another thread may be finishing execution
which could be inefficient and cause conflicts. With less iterations
the threads are more likely to complete time slices and lead to less errors.
-With more iterations we produce more likelihood or race condition
by providing many options to the scheduler.
-Many threads means many divisions of the main task, so there are more
likely to have smaller poritions completed in any given threads turn.

+Small numbers of iterations seldom fail because the threads are likely
to complete the accumulation (few threads accessing and adding the variable)
within one time slice. Thus, the race condition is hardly observed since
they are more likely to complete their task in fewer, but larger portions.

*2.1.2

-Yields run slower due to the context switchting that occurrs between
the interrupting and resecheduling of threads. This carries overhead.
-Without yield we expect a frequency of context switches that is dependant
on the number of threads.
-When yield is applied dependancy is placed on the context swithces arising
from our add function (-1 and 1, so happens two times) followed by another
switch to after a thread completes its task

-The additional time is spent switching between the threads

-No, it is not possible to get valid per-operation timings using yield.
-We may not determine the actual time required for context switches and
the actual real frequency in which they occur.
-We do our best to simulate it with counters and clocks, but the number
depends on the system and more complex low level features.
-The below source concludes that measuring sprints is difficult, factors
can lead to inaccuracies for thousands of instructions, and accuracy is
affected by runtime duration and number of threads etc.
Source:http://sape.inf.usi.ch/sites/default/files/publication/ispass09.pdf

*2.1.3
-The average cost per operation drops with increasing iterations because the
overhead of creating the threads becomes reduced to a lower average over time.
-Similar to starting economics the fixed cost can begin at a high price, but
over time the performance of your system or business can reduce that average.
-So the creation of threads (fixed time aka fixed cost is split about the
many operations (similarly increasing iterations), thus the average cost per op
decreases as the iterations increase.

-We can deduce a somewhat accurate correct cost by letting the limit of iterations
approach extremely large values.
-At this point our fixed cost can be deemed theoretically insignificant and we
can look at the total cost as a function based on other factors and determine a
very nearly correct answer or cost.
-However, this is theoretical and although we can minimize this process, we will
still have a fixed cost even if it is marginal compared to the total cost value.

*2.1.4
-For low number of threads the overhead incurred for each of the options is
lower and thus they perform similarly.
-This can be attributed to them performing less frequently. This is eventually
outweighed for each option as the number of threads increases and adds the
overhead for switching, blocking, and waiting to run.

-Protected operations slow down with the increase of threads because of the time
spent trying to access the shared data.
-At any point in time one thread may have locked the variable and the others
may be waiting or blocked (possibly unable to perform any other tasks). This
leads to wasted time or inefficiencies.
-Further, the increase of context switches can be a factor too.
-Thus, there are several ways in which we trade security for performance (or vice
versa).

*2.2.1
-In comparing the variation in time per mutex protected ops vs number of
threads we can see that the threads and mutex protected operations share
a positive correllation in Part 1.
-Part 1 both cost and threads increase together, starting with a steeper
climb, but then becoming more flat as the threads increase
-This can be explained from more threads all trying to access the mutex
-In Part 2 an increase in threads does not clearly change the the cost of
mutex protected operations.
-In this graph the line appears more flat and as if it remains near constant
as threads increase.
-This is also reasonable since the overhead of the operations in the linked
list is likely more comupationally expensive the the threads fighting for
acquisition of the locks/mutex, and the time spent during that process.

*2.2.2
-For both mutexes and spinlocks we notice a increase in cost with the threads
(positive correlation).
-The rate for these is different though possibly due to how each are implemented
and their associated costs.
-Spinlocks waste time spinning ("waiting") until they get the lock
-Mutexes allow for blocking that can allow other threads to take that threads
position in queue to grab the lock and start working.
-To clarify the CPU can ignore a mutex that is waiting for a locked critical
section so it does not waste the same time spinning.

-Notice our explanations are supported by the graphs
-The spinlocks both rise above the mutexes, but in the list they stay at a more
linear growth while the add has a curve. The curve appears to start flattening a
bit.
-The mutexes are increasing also. In the add graph the curve is flatter and
flattens more quickly. In the list graph the mutex is practically flat to start.
-For initial costs: In the list graph the mutexes and spin locks start around
the same cost, but in the add graph the spin locks appear cheaper, but quickly
become more expensive around 2 threads.
-Thus, we see see the difference in lock methods inherent cost and how the avg
operation cost is less for mutexes generally over time.

Files:
lab2_add.c:
*The C program to implement shared variable add function

lab2_list.c:
*C program to run the doubly linked list and perform the tests
*Uses both SortedList.c and SortedList.h functionality.

SortedList.h:
*Provided by Lab to outline function for the list.c program and SortedList.c
*These functions are linked and used to carry out the Sorted Linked List

SortedList.c:
*C program to implement the code for insert, lookup, length and delete
*Fulfills the code provided in SortedList.h

lab2_add.csv: 
*Table containing values from running 'make tests' from the makefile
*This has the lab2_add.gp grep and extract information to create PNG files

lab2_list.csv:
*Table containing values from running 'make tests' from the makefile
*This has the lab2_list.gp grep and extract information to create PNG files

lab2_add.gp 
*execute gnuplot to graph values from the csv files for lab2_add
*can run this using the makefile to generate the graphs
*this file is provided by Lab

lab2_list.gp
*execute gnuplot to graph values from the csv files for lab2_list
*can run this using the makefile to generate the graphs
*this file is provided by Lab

Makefile
*default and *build - build lab2_add , lab2_list from C programs
*graphs - execute gnuplot using provided scripts: lab2_add.gp , lab2_list.gp
*dist - creates tarball for submission
*tests - tests lab2_add , lab2_list, values are sent to csv files
*clean - removes programs created by Makefile

Resources:
Pthreads:
https://www.youtube.com/watch?v=sD__p9cbQpc
https://computing.llnl.gov/tutorials/pthreads/

Compare and Swap:
https://gcc.gnu.org/onlinedocs/gcc-4.1.1/gcc/Atomic-Builtins.html

Clockgettime:
http://man7.org/linux/man-pages/man2/clock_getres.2.html

man pages: clock_gettime(2), gnuplot(1)

GCC atomic builtins

Doubly Linked List:
https://www.geeksforgeeks.org/insert-value-sorted-way-sorted-doubly-linked-list/
https://stackoverflow.com/questions/43086771/linked-list-how-to-sort-doubly-linked-list
https://www.tutorialspoint.com/data_structures_algorithms/doubly_linked_list_algorithm.htm

Arpaci Book

Questions on performance:
http://sape.inf.usi.ch/sites/default/files/publication/ispass09.pdf
